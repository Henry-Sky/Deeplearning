{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import unicodedata\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data\n",
    "from common_tools import set_seed\n",
    "\n",
    "set_seed(1)  # 设置随机种子\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters)\n",
    "\n",
    "\n",
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i\n",
    "\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)                 # 选类别\n",
    "    line = randomChoice(category_lines[category])           # 选一个样本\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = lineToTensor(line)    # str to one-hot\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "# Just return an output given a line\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def predict(input_line, n_predictions=3):\n",
    "    print('\\n> %s' % input_line)\n",
    "    with torch.no_grad():\n",
    "        output = evaluate(lineToTensor(input_line))\n",
    "\n",
    "        # Get top N categories\n",
    "        topv, topi = output.topk(n_predictions, 1, True)\n",
    "\n",
    "        for i in range(n_predictions):\n",
    "            value = topv[0][i].item()\n",
    "            category_index = topi[0][i].item()\n",
    "            print('(%.2f) %s' % (value, all_categories[category_index]))\n",
    "\n",
    "\n",
    "def get_lr(iter, learning_rate):\n",
    "    lr_iter = learning_rate if iter < n_iters else learning_rate*0.1\n",
    "    return lr_iter\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.u = nn.Linear(input_size, hidden_size)\n",
    "        self.w = nn.Linear(hidden_size, hidden_size)\n",
    "        self.v = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "\n",
    "        u_x = self.u(inputs)\n",
    "\n",
    "        hidden = self.w(hidden)\n",
    "        hidden = self.tanh(hidden + u_x)\n",
    "\n",
    "        output = self.softmax(self.v(hidden))\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    # 第一次参数初始化为零\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "    # 加载数据到指定设备\n",
    "    line_tensor = line_tensor.to(device)\n",
    "    hidden = hidden.to(device)\n",
    "    category_tensor = category_tensor.to(device)\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # config\n",
    "    path_txt = os.path.join(enviroments.names,\"*.txt\")\n",
    "    all_letters = string.ascii_letters + \" .,;'\"\n",
    "    n_letters = len(all_letters)    # 52 + 5 字符总数\n",
    "    print_every = 5000\n",
    "    plot_every = 5000\n",
    "    learning_rate = 0.005\n",
    "    n_iters = 200000\n",
    "\n",
    "    # step 1 data\n",
    "    # Build the category_lines dictionary, a list of names per language\n",
    "    category_lines = {}\n",
    "    all_categories = []\n",
    "    for filename in glob.glob(path_txt):\n",
    "        category = os.path.splitext(os.path.basename(filename))[0]\n",
    "        all_categories.append(category)\n",
    "        lines = readLines(filename)\n",
    "        category_lines[category] = lines\n",
    "\n",
    "    n_categories = len(all_categories)\n",
    "\n",
    "    # step 2 model\n",
    "    n_hidden = 128\n",
    "    # rnn = RNN(n_letters, n_hidden, n_categories)\n",
    "    rnn = RNN(n_letters, n_hidden, n_categories)\n",
    "\n",
    "    rnn.to(device)\n",
    "\n",
    "    # step 3 loss\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    # step 4 optimize by hand\n",
    "\n",
    "    # step 5 iteration\n",
    "    current_loss = 0\n",
    "    all_losses = []\n",
    "    start = time.time()\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        # sample\n",
    "        category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "\n",
    "        # training\n",
    "        output, loss = train(category_tensor, line_tensor)\n",
    "\n",
    "        current_loss += loss\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iter % print_every == 0:\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "            print('Iter: {:<7} time: {:>8s} loss: {:.4f} name: {:>10s}  pred: {:>8s} label: {:>8s}'.format(\n",
    "                iter, timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iter % plot_every == 0:\n",
    "            all_losses.append(current_loss / plot_every)\n",
    "            current_loss = 0\n",
    "path_model = os.path.join(BASE_DIR, \"rnn_state_dict.pkl\")\n",
    "torch.save(rnn.state_dict(), path_model)\n",
    "plt.plot(all_losses)\n",
    "plt.show()\n",
    "\n",
    "predict('Yue Tingsong')\n",
    "predict('Yue tingsong')\n",
    "predict('yutingsong')\n",
    "\n",
    "predict('test your name')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
