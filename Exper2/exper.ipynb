{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 了解简单的CNN网络的工作原理，并实现LeNet5模型，实现手写数字识别功能。\n",
    "- 使用MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # 层\n",
    "        self.c1 = nn.Conv2d(1, 6, 5, 1, 2)\n",
    "        self.s2 = nn.AvgPool2d(2,2)\n",
    "        self.c3 = nn.Conv2d(6, 16, 5)\n",
    "        self.s4 = nn.AvgPool2d(2,2)\n",
    "        self.c5 = nn.Conv2d(16, 120, 5)\n",
    "        self.f6 = nn.Linear(120, 84)\n",
    "        self.output = nn.Linear(84, 10)\n",
    "        # 函数\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.flatten = nn.Flatten(1, -1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.c1(x))\n",
    "        x = self.s2(x)\n",
    "        x = self.sigmoid(self.c3(x))\n",
    "        x = self.s4(x)\n",
    "        x = self.c5(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.f6(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据精度转换  \n",
    "tensor.type(torch.float64)  \n",
    "模型精度转换  \n",
    "torch.set_default_dtype(torch.float64)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# #load data\n",
    "# transform = torchvision.transforms.ToTensor()  #定义数据预处理方式：转换 PIL.Image 成 torch.FloatTensor\n",
    " \n",
    "# train_data = torchvision.datasets.MNIST(root=\"./data/\",    #数据目录，这里目录结构要注意。\n",
    "#                                         train=True,                                     #是否为训练集\n",
    "#                                         transform=transform,                            #加载数据预处理\n",
    "#                                         download=True)                                 #是否下载\n",
    "\n",
    "# test_data = torchvision.datasets.MNIST(root=\"./data/\",\n",
    "#                                         train=False,\n",
    "#                                         transform=transform,\n",
    "#                                         download=True)\n",
    "# #数据加载器:组合数据集和采样器 \n",
    "# train_loader = DataLoader(dataset = train_data, batch_size = 64, shuffle = True) \n",
    "# test_loader = DataLoader(dataset = test_data, batch_size = 64, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataload import *\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = torch.from_numpy(decode_idx3_ubyte(\"./data/train-images.idx3-ubyte\")).double()\n",
    "train_lab = torch.from_numpy(decode_idx1_ubyte(\"./data/train-labels.idx1-ubyte\")).double()\n",
    "train_set = TensorDataset(train_data, train_lab)\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "test_data = torch.from_numpy(decode_idx3_ubyte(\"./data/t10k-images.idx3-ubyte\")).double()\n",
    "test_lab = torch.from_numpy(decode_idx1_ubyte(\"./data/t10k-labels.idx1-ubyte\")).double()\n",
    "test_set = TensorDataset(test_data, test_lab)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss\n",
    "net = LeNet5().cuda()   #实例化网络，有GPU则将网络放入GPU加速\n",
    "loss_func = nn.CrossEntropyLoss()    #多分类问题，选择交叉熵损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum = 0.9)   #选择SGD，学习率取0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n",
      "torch.cuda.DoubleTensor\n"
     ]
    }
   ],
   "source": [
    "from tqdm import*\n",
    "\n",
    "#开始训练\n",
    "EPOCH = 5   #迭代次数\n",
    "for epoch in tqdm(range(EPOCH)):\n",
    "    sum_loss = 0\n",
    "    #数据读取\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        print(inputs.type())\n",
    " \n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        # 传递损失 + 更新参数\n",
    "        output = net(inputs)\n",
    "        loss = loss_func(output, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "    correct = 0\n",
    "    total = 0\n",
    " \n",
    "    for data in test_loader:\n",
    "        test_inputs, labels = data\n",
    "        test_inputs, labels = test_inputs.cuda(), labels.cuda()\n",
    "\n",
    "        outputs_test = net(test_inputs)\n",
    "\n",
    "        _, predicted = torch.max(outputs_test.data, 1)  #输出得分最高的类\n",
    "        total += labels.size(0) #统计50个batch 图片的总个数\n",
    "        correct += (predicted == labels).sum()  #统计50个batch 正确分类的个数\n",
    " \n",
    "    print('第{}个epoch的识别准确率为:{}%'.format (epoch + 1, 100*correct.item()/total))\n",
    "\n",
    "# 模型保存\n",
    "# torch.save(net.state_dict(),'./Model') \n",
    "\n",
    "# 模型加载\n",
    "# net.load_state_dict(torch.load('ckpt.mdl'))\n",
    "\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
